[
  {
    "objectID": "program.html",
    "href": "program.html",
    "title": "China Pharma RUG Meeting Program",
    "section": "",
    "text": "Dynamic CDISC Analysis Results Data with the R Packages {cards} and {gtsummary}\nDaniel Sjoberg, Roche\nABSTRACTThe CDISC Analysis Results Data (ARD) Model is an emerging standard for encoding statistical analysis outcomes in a machine-readable format. Its primary objective is to streamline the processes of automation, ensuring reproducibility, promoting reusability, and enhancing traceability.\nThe {cards} R package offers a range of functions for ARD generation, from basic univariate summaries like means and tabulations to complex multivariable summaries encompassing regression models and statistical tests.\nThe package includes functionalities to represent results in various formats, including JSON and YAML. Thanks to its flexible structures, the {cards} package can be harnessed in diverse applications, such as generating tables for regulatory submissions and conducting quality control checks on existing tables. Furthermore, the {cards} ARD object can be accessed through a REST API, allowing writers to dynamically incorporate table results into reports.\nWhile {cards} calculates statistics and stores them in a structured object, it cannot present those results; this, however, is where the {gtsummary} package shines. The {gtsummary} package offers a modular framework to construct summary tables. It is the most widely used package for summary tables in the healthcare/pharmaceutical space, and won the American Statistical Association’s 2021 award for Innovation in Statistical Programming and Analytics. The {gtsummary} package is currently being refactored to utilize {cards} as its backend, which will allow users to both extract an ARD object from a {gtsummary} table and use an ARD object to construct a {gtsummary} table.\nThe {cards} and {gtsummary} packages stand as robust and versatile tools, poised to assist in a multitude of analytical endeavors.\n\n\nOptimize decision-making efficiency and speed by performing exploratory analysis through the MedDRAH platform\nHuadan Li, Zhiping Yan, Dizal\nABSTRACTMedical Data Review and Analysis Hub (MedDRAH /’med’ra:/) is an interactive Web-based real-time clinical trial data monitoring and analysis platform that enables Medical and PV Physicians, Statisticians, and PK Scientists to review, analyze, and generate reports through intuitive point-and-click wizards. The functions below are included in MedDRAH: Review real-time EDC and SDTM data; Generate visual reports for medical data review; Perform comprehensive exploratory analysis utilizing a complete suite of analysis and reporting (A & R) tools; Create the patient narratives; Conduct standardized pharmacokinetic statistical analyses, including assessments of dose-proportionality, food/fed effects, drug-drug interactions (DDI), and exposure-response (E-R) relationships. This presentation will introduce how to design and develop such platform by using R and JavaScript.\n\n\nLeveraging R for Real-Time Data Analysis and Reporti+L7ng in the AI+HI Paradigm\nHao Chen, Beigene\nABSTRACTR is an excellent programming language for data analysis and reporting, featuring a mature platform developed by Posit@ and a thriving ecosystem within the pharmaceutical industry.\nBeing open-source, R offers an extensive codebase that allows AI to learn and improve. This enables the automation of R code comprehension and generation through AI, offering significant potential for the development of AI-powered R applications.\nIn parallel, R Shiny offers a superb UI framework that enhances human-computer interaction, integrating AI with human intelligence seamlessly. This presents a valuable opportunity to leverage R for real-time data analysis and reporting within the AI+HI paradigm.\nIn our presentation, we will showcase a R Shiny application designed to demonstrate this concept. We will illustrate how this integrated approach can significantly improve efficiency and decision-making in our daily work.\n\n\nFrom XPT to Dataset-JSON as Alternative Transport Format for Regulatory Submission in R\nHuan Lu, Neo Yang, Sanofi\nABSTRACTCDISC and PHUSE announced a new pilot project aimed at supporting the adoption of Dataset-JSON as an alternative transport format for replacing XPT as the default file format for clinical and device data submissions to regulatory authorities. New standards will be able to take advantage of enhanced capabilities, and drive efficiencies, consistency, and re-usability across the clinical research data life cycle. To leverage the features of Dataset-JSON has become the key for future development of CDISC foundational standards, this presentation will show how R can work with Dataset-JSON, both reading and writing.\n\n\nDaVinci Journey in the Early Phase Oncology Study\nYifan Han, Boehringer Ingelheim\nABSTRACTWhat is DaVinci? DaVinci is an innovative solution at Boehringer Ingelheim to provide Data Access and dynamic Visualization for clinical insight. It enables real time access to clinical trial data and provides tools to review, aggregate and visualize data, which further fastens drug development. Apps Multiple Apps were developed and deployed under DaVinci ecosystem. Then they were put into practice and served teams for different purpose. For instance, EBAS mainly focuses on Exploratory Biomarker data Analysis, RENOVATE provides insights in terms of efficacy and Modular DaVinci paves the way for medicine team to monitor data. Moreover, DaVinci ecosystem renders flexibilities for users to include additional customized modules. RENOVATE RECIST (v1.1) based data moNitOring Visualization and Analytics Tool for Efficacy RENOVATE is an effective tool to generate evidence from POCP studies. It enables fast decision making for late phase development. It could help visualize the response data, monitor study data during the trial conduct and detect early efficacy signal, etc.\n\n\nRShiny tool: TDM automation\nHao Huang, Novartis\nABSTRACTThe SDTM Trial Design Model (TDM) is a required part of all CDISC SDTM electronic data submissions. Many colleagues find the TDM creation to be time-consuming and tedious due to a lot of \"copy-paste\" repetitive work. Additionally, some may feel uncomfortable with the Trial Summary (TS) domain. To enhance the experience of creating TDM for colleagues, we have developed an R ShinyApp-based automation tool, where users only need to upload the study protocol, and the tool will automatically extract the TDM information from protocol using regular expressions. Finally, the tool exports an Excel TDM report for downstream use. The tool also offers optional input fields and customized options to support the creation of a more study specific TDM report. Using this tool, users can easily obtain all the required TS parameter and most commonly used parameters for TS. It also highlights IETEST length over 200 and automatically converts special characters, etc. In practice, it takes only 10 to 40 seconds to complete the task with an acceptable accuracy rate. This tool can significantly enhance your work efficiency and improve your experience of working with TDM in daily work.\n\n\nAuto Subgroup TLG Generation With R Shiny\nYufan Chen, J&J\nABSTRACTWith the aim of eliminating gaps in patient access to new and innovative treatments developed in global pipeline, subgroup analysis for regulatory submission based on multi-regional clinical trial (MRCT) has been conducted more and more frequently by global pharmaceutical companies. The workflow of a subgroup analysis for a statistical programmer includes modifying existing programs from MRCT by performing analysis on a subset of the subjects’ population which involves highly repetitive manual work.   This presentation will introduce an automatic approach to modify programs in subgroup analysis. In this new workflow, statistical programmers are armed with a tool that can automate the generation of programs which are ready to be executed to create the outputs that fit the needs of regional regulators. Compared to updating programs one after another manually, this automatic tool helps to improve the efficiency and quality of subgroup analysis. Moreover, the tool can be utilized to produce subgroup versions of programs for any subgroup potentially, i.e., subgroup by sex or age groups.\n\n\nSAS datasets comparison using R shiny app\nWeiwei Jiao, MSD\nABSTRACTA common task for programmers and statisticians is to compare SAS datasets in different folders, which traditionally requires the opening of SAS software and the writing of SAS code. While this is a simple process, it can be time-consuming when performed on a regular basis. The proposed solution leverages the R shiny app to compare SAS datasets, requiring only the input of the SAS dataset path and a simple click to generate comparison results, thus saving both time and effort. The paper will detail different methods of implementing this comparison via the R shiny app and will evaluate the respective advantages and disadvantages of each method.\n\n\nMediSum Shiny-App: Interactive Data Summarising using Raw Data\nJingya Wang, Hengrui\nABSTRACTIn response to the increasing demand for medical reviews and the need for concise data summaries, we developed a SHINY-APP focusing on generating comprehensive tables and plots directly from EDC raw data. Currently supporting demographic tables, adverse event summaries, tumor-related efficacy analyses (e.g., KM plots, waterfall plots), and more. This tool utilizes a JSON-based spec as a guide, allowing adaptability to changes in EDC versions through spec modifications. Furthermore, our app integrates well-known R packages like rtables, tplyr, r2rtf, and Biogen’s filter module, enhancing its versatility in data exploration and analysis.\n\n\nChevron: A open-source package to facilitate generation of outputs\nLiming Li, Roche\nABSTRACTWithin the NEST family, we already open-sourced a lot of packages to as the backbone of clinical reporting, including rtables, tern. On top of that, we also have tlg-catalog serving as an example to facilitate the generation of outputs. However, many outputs are standard across multiple studies, and there are only minimal differences across studies. To reduce the effort to create these outputs, we developed a new package, chevron, to bring standard in a user-friendly manner. With chevron, the standards are easily implemented in a scaled manner. Chevron has already been used within Roche in multiple projects. We have also open-sourced chevron to better support you generating the outputs.\n\n\nR Shiny Tool for Mayo Score Monitoring in UC Study\nShaoming Liu, Pfizer\nABSTRACTMayo score is the primary endpoint for UC studies. It includes sub-component of stool frequency and rectal bleeding with raw data collected in daily diary. Calculation of this sub-component for mayo score involves selection of valid days among daily diary data based on bowel preparation date and endoscopy date. It also includes sub-component of endoscopic readings from multiple readers and adjudication. UC study targeting on population with certain UC severity involves inclusion criteria pertaining to disease characteristics, such as inclusion of participants with a 5 to 9 score on the mMS (modified Mayo Score) including an endoscopy sub-score of at least 2, which requires study team to calculate mayo score at screening and/or baseline. This R shiny app is a visualized tool which facilitates study team with mayo score monitoring from various perspective and purposes, including individual daily diary quality check of valid days and sub-scores, review of endoscopic reader’s consistency, visualization of mayo score and its sub-component over time. It provides real-time monitoring to enable study team with participants inclusion verification, direct interaction with data, simplified view of complex data from multiple sources, and enhanced knowledge of patterns and trends. Excellent and plaudit feedback for this tool has been received for this tool from study team.\n\n\nCreate TLGs and log files by sassy\nPerphy Zhao, Sanofi\nABSTRACTThis paper aims to introduce a newer package called sassy that makes R easier, especially pure SAS programmers to create TLGs and logfiles. This package is a meta-package brings several SAS concept to R, and the programming grammar is highly similar with SAS, including libr which gives programmer the ability to define libnames, generate data dictionaries, and simulate data steps, fmtr which provides functions for formatting data and creating format catalogs, procs which is a set of functions that simulate SASprocedures and includes simulations of FREQ, MEANS, TRANSPOSE, SORT and PRINT procedures, reporter which is a reporting package with easy layout capabilities and the ability to write reports in RTF, DOCX, TXT and HTML file formats, logr which produces a traceable log files, common which is a set of utility functions across the sassy family packages, and often useful in their own right."
  },
  {
    "objectID": "program.html#program",
    "href": "program.html#program",
    "title": "China Pharma RUG Meeting Program",
    "section": "",
    "text": "Time\nTopic\nPresenter\nLocation\n\n\n\n\n8:30-9:00\nRegistration\n\n\n\n\n9:00-9:10\nWelcome\nJoe Zhu, Roche; Wang Zhang, MSD\nBeijing, Shanghai\n\n\n9:10-9:20\nOpening Remarks\nYan Qiao, BeiGene\nBeijing\n\n\n9:20-9:50\n Dynamic CDISC Analysis Results Data with the R Packages {cards} and {gtsummary}\nDaniel Sjoberg, Roche\nOn-Line\n\n\n9:50-10:20\nOptimize decision-making efficiency and speed by performing exploratory analysis through the MedDRAH platform\nHuadan Li, Zhiping Yan, Dizal\nBeijing\n\n\n10:20-10:50\nBreak\n\n\n\n\n10:50-11:10\nLeveraging R for Real-Time Data Analysis and Reporti+L7ng in the AI+HI Paradigm\nHao Chen, Beigene\nShanghai\n\n\n11:10-11:30\nFrom XPT to Dataset-JSON as Alternative Transport Format for Regulatory Submission in R\nHuan Lu, Neo Yang, Sanofi\nBeijing\n\n\n11:30-12:00\nDaVinci Journey in the Early Phase Oncology Study\nYifan Han, Boehringer Ingelheim\nShanghai\n\n\n12:00-13:00\nLunch Break\n\n\n\n\n13:00-13:30\nRShiny tool: TDM automation\nHao Huang, Novartis\nShanghai\n\n\n13:30-14:00\nAuto Subgroup TLG Generation With R Shiny\nYufan Chen, J&J\nShanghai\n\n\n14:00-14:30\nSAS datasets comparison using R shiny app\nWeiwei Jiao, MSD\nBeijing\n\n\n14:30-15:00\nMediSum Shiny-App: Interactive Data Summarising using Raw Data\nJingya Wang, Hengrui\nShanghai\n\n\n15:00-15:30\nBreak\n\n\n\n\n15:30-16:00\nChevron: A open-source package to facilitate generation of outputs\nLiming Li, Roche\nShanghai\n\n\n16:00-16:30\nR Shiny Tool for Mayo Score Monitoring in UC Study\nShaoming Liu, Pfizer\nShanghai\n\n\n16:30-16:55\nCreate TLGs and log files by sassy\nPerphy Zhao, Sanofi\nBeijing\n\n\n16:55-17:20\nPending\nPending\nPending\n\n\n17:20-17:30\nClosing Remarks\nYanli Chang, Novartis\nShanghai\n\n\n\n\n\nDaniel Sjoberg, Roche\nABSTRACTThe CDISC Analysis Results Data (ARD) Model is an emerging standard for encoding statistical analysis outcomes in a machine-readable format. Its primary objective is to streamline the processes of automation, ensuring reproducibility, promoting reusability, and enhancing traceability.\nThe {cards} R package offers a range of functions for ARD generation, from basic univariate summaries like means and tabulations to complex multivariable summaries encompassing regression models and statistical tests.\nThe package includes functionalities to represent results in various formats, including JSON and YAML. Thanks to its flexible structures, the {cards} package can be harnessed in diverse applications, such as generating tables for regulatory submissions and conducting quality control checks on existing tables. Furthermore, the {cards} ARD object can be accessed through a REST API, allowing writers to dynamically incorporate table results into reports.\nWhile {cards} calculates statistics and stores them in a structured object, it cannot present those results; this, however, is where the {gtsummary} package shines. The {gtsummary} package offers a modular framework to construct summary tables. It is the most widely used package for summary tables in the healthcare/pharmaceutical space, and won the American Statistical Association’s 2021 award for Innovation in Statistical Programming and Analytics. The {gtsummary} package is currently being refactored to utilize {cards} as its backend, which will allow users to both extract an ARD object from a {gtsummary} table and use an ARD object to construct a {gtsummary} table.\nThe {cards} and {gtsummary} packages stand as robust and versatile tools, poised to assist in a multitude of analytical endeavors.\n\n\n\nHuadan Li, Zhiping Yan, Dizal\nABSTRACTMedical Data Review and Analysis Hub (MedDRAH /’med’ra:/) is an interactive Web-based real-time clinical trial data monitoring and analysis platform that enables Medical and PV Physicians, Statisticians, and PK Scientists to review, analyze, and generate reports through intuitive point-and-click wizards. The functions below are included in MedDRAH: Review real-time EDC and SDTM data; Generate visual reports for medical data review; Perform comprehensive exploratory analysis utilizing a complete suite of analysis and reporting (A & R) tools; Create the patient narratives; Conduct standardized pharmacokinetic statistical analyses, including assessments of dose-proportionality, food/fed effects, drug-drug interactions (DDI), and exposure-response (E-R) relationships. This presentation will introduce how to design and develop such platform by using R and JavaScript.\n\n\n\nHao Chen, Beigene\nABSTRACTR is an excellent programming language for data analysis and reporting, featuring a mature platform developed by Posit@ and a thriving ecosystem within the pharmaceutical industry.\nBeing open-source, R offers an extensive codebase that allows AI to learn and improve. This enables the automation of R code comprehension and generation through AI, offering significant potential for the development of AI-powered R applications.\nIn parallel, R Shiny offers a superb UI framework that enhances human-computer interaction, integrating AI with human intelligence seamlessly. This presents a valuable opportunity to leverage R for real-time data analysis and reporting within the AI+HI paradigm.\nIn our presentation, we will showcase a R Shiny application designed to demonstrate this concept. We will illustrate how this integrated approach can significantly improve efficiency and decision-making in our daily work.\n\n\n\nHuan Lu, Neo Yang, Sanofi\nABSTRACTCDISC and PHUSE announced a new pilot project aimed at supporting the adoption of Dataset-JSON as an alternative transport format for replacing XPT as the default file format for clinical and device data submissions to regulatory authorities. New standards will be able to take advantage of enhanced capabilities, and drive efficiencies, consistency, and re-usability across the clinical research data life cycle. To leverage the features of Dataset-JSON has become the key for future development of CDISC foundational standards, this presentation will show how R can work with Dataset-JSON, both reading and writing.\n\n\n\nYifan Han, Boehringer Ingelheim\nABSTRACTWhat is DaVinci? DaVinci is an innovative solution at Boehringer Ingelheim to provide Data Access and dynamic Visualization for clinical insight. It enables real time access to clinical trial data and provides tools to review, aggregate and visualize data, which further fastens drug development. Apps Multiple Apps were developed and deployed under DaVinci ecosystem. Then they were put into practice and served teams for different purpose. For instance, EBAS mainly focuses on Exploratory Biomarker data Analysis, RENOVATE provides insights in terms of efficacy and Modular DaVinci paves the way for medicine team to monitor data. Moreover, DaVinci ecosystem renders flexibilities for users to include additional customized modules. RENOVATE RECIST (v1.1) based data moNitOring Visualization and Analytics Tool for Efficacy RENOVATE is an effective tool to generate evidence from POCP studies. It enables fast decision making for late phase development. It could help visualize the response data, monitor study data during the trial conduct and detect early efficacy signal, etc.\n\n\n\nHao Huang, Novartis\nABSTRACTThe SDTM Trial Design Model (TDM) is a required part of all CDISC SDTM electronic data submissions. Many colleagues find the TDM creation to be time-consuming and tedious due to a lot of \"copy-paste\" repetitive work. Additionally, some may feel uncomfortable with the Trial Summary (TS) domain. To enhance the experience of creating TDM for colleagues, we have developed an R ShinyApp-based automation tool, where users only need to upload the study protocol, and the tool will automatically extract the TDM information from protocol using regular expressions. Finally, the tool exports an Excel TDM report for downstream use. The tool also offers optional input fields and customized options to support the creation of a more study specific TDM report. Using this tool, users can easily obtain all the required TS parameter and most commonly used parameters for TS. It also highlights IETEST length over 200 and automatically converts special characters, etc. In practice, it takes only 10 to 40 seconds to complete the task with an acceptable accuracy rate. This tool can significantly enhance your work efficiency and improve your experience of working with TDM in daily work.\n\n\n\nYufan Chen, J&J\nABSTRACTWith the aim of eliminating gaps in patient access to new and innovative treatments developed in global pipeline, subgroup analysis for regulatory submission based on multi-regional clinical trial (MRCT) has been conducted more and more frequently by global pharmaceutical companies. The workflow of a subgroup analysis for a statistical programmer includes modifying existing programs from MRCT by performing analysis on a subset of the subjects’ population which involves highly repetitive manual work.   This presentation will introduce an automatic approach to modify programs in subgroup analysis. In this new workflow, statistical programmers are armed with a tool that can automate the generation of programs which are ready to be executed to create the outputs that fit the needs of regional regulators. Compared to updating programs one after another manually, this automatic tool helps to improve the efficiency and quality of subgroup analysis. Moreover, the tool can be utilized to produce subgroup versions of programs for any subgroup potentially, i.e., subgroup by sex or age groups.\n\n\n\nWeiwei Jiao, MSD\nABSTRACTA common task for programmers and statisticians is to compare SAS datasets in different folders, which traditionally requires the opening of SAS software and the writing of SAS code. While this is a simple process, it can be time-consuming when performed on a regular basis. The proposed solution leverages the R shiny app to compare SAS datasets, requiring only the input of the SAS dataset path and a simple click to generate comparison results, thus saving both time and effort. The paper will detail different methods of implementing this comparison via the R shiny app and will evaluate the respective advantages and disadvantages of each method.\n\n\n\nJingya Wang, Hengrui\nABSTRACTIn response to the increasing demand for medical reviews and the need for concise data summaries, we developed a SHINY-APP focusing on generating comprehensive tables and plots directly from EDC raw data. Currently supporting demographic tables, adverse event summaries, tumor-related efficacy analyses (e.g., KM plots, waterfall plots), and more. This tool utilizes a JSON-based spec as a guide, allowing adaptability to changes in EDC versions through spec modifications. Furthermore, our app integrates well-known R packages like rtables, tplyr, r2rtf, and Biogen’s filter module, enhancing its versatility in data exploration and analysis.\n\n\n\nLiming Li, Roche\nABSTRACTWithin the NEST family, we already open-sourced a lot of packages to as the backbone of clinical reporting, including rtables, tern. On top of that, we also have tlg-catalog serving as an example to facilitate the generation of outputs. However, many outputs are standard across multiple studies, and there are only minimal differences across studies. To reduce the effort to create these outputs, we developed a new package, chevron, to bring standard in a user-friendly manner. With chevron, the standards are easily implemented in a scaled manner. Chevron has already been used within Roche in multiple projects. We have also open-sourced chevron to better support you generating the outputs.\n\n\n\nShaoming Liu, Pfizer\nABSTRACTMayo score is the primary endpoint for UC studies. It includes sub-component of stool frequency and rectal bleeding with raw data collected in daily diary. Calculation of this sub-component for mayo score involves selection of valid days among daily diary data based on bowel preparation date and endoscopy date. It also includes sub-component of endoscopic readings from multiple readers and adjudication. UC study targeting on population with certain UC severity involves inclusion criteria pertaining to disease characteristics, such as inclusion of participants with a 5 to 9 score on the mMS (modified Mayo Score) including an endoscopy sub-score of at least 2, which requires study team to calculate mayo score at screening and/or baseline. This R shiny app is a visualized tool which facilitates study team with mayo score monitoring from various perspective and purposes, including individual daily diary quality check of valid days and sub-scores, review of endoscopic reader’s consistency, visualization of mayo score and its sub-component over time. It provides real-time monitoring to enable study team with participants inclusion verification, direct interaction with data, simplified view of complex data from multiple sources, and enhanced knowledge of patterns and trends. Excellent and plaudit feedback for this tool has been received for this tool from study team.\n\n\n\nPerphy Zhao, Sanofi\nABSTRACTThis paper aims to introduce a newer package called sassy that makes R easier, especially pure SAS programmers to create TLGs and logfiles. This package is a meta-package brings several SAS concept to R, and the programming grammar is highly similar with SAS, including libr which gives programmer the ability to define libnames, generate data dictionaries, and simulate data steps, fmtr which provides functions for formatting data and creating format catalogs, procs which is a set of functions that simulate SASprocedures and includes simulations of FREQ, MEANS, TRANSPOSE, SORT and PRINT procedures, reporter which is a reporting package with easy layout capabilities and the ability to write reports in RTF, DOCX, TXT and HTML file formats, logr which produces a traceable log files, common which is a set of utility functions across the sassy family packages, and often useful in their own right."
  },
  {
    "objectID": "program.html#abstract",
    "href": "program.html#abstract",
    "title": "Open Source Clinical Reporting summeR (2023-August-29)",
    "section": "Abstract",
    "text": "Abstract\n\nReporting tables form a central component of regulatory filings in the pharmaceutical industry\nGabe Becker\nThese tables are often complex, both in their conceptual structure and in the computations required to generate their individual cell values. Gabe will introduce the rtables package and show how visualization concepts, particularly faceting and the grammar of graphics, apply to tables generally and inform rtables’ ability to succinctly declare and create complex structured tables such as those included in clinical trial filings. Gabe will also give a brief update of the work of the R Consortium’s R Tables For Regulatory Submission (RTRS) working group.\n\n\nApply next-generation tools in real study\nLiu Jia (Roche)\nOur real study focuses on chronic hepatitis B (CHB) virus infection. The programming team of this study is a mix of advanced R programmers and novices. The team explored using R based tools, OAK and Admiral, to support SDTMv and ADAM QC. Through the exploration and application, the team has gained lots of valuable experience on next-generation tools. Roche is diligent to work on “next-generation” solutions for our data and analytics platforms to move towards increased automation. Next-generation tools OAK and Admiral are good examples. Admiral, toolbox for programming Clinical Data Interchange Standards Consortium (CDISC) compliant Analysis Data Model (ADaM) datasets in R. The OAK Garden aims to automate the clinical data flow from Data Collection to Data Tabulation thereby automating the study of SDTMv Datasets, SDTMv specifications, eSubmission Deliverables SDTM xpt files & SDTM Define.xml. With the help and inspiration of developers and other users, the team has overcame lots of difficulties and gained valuable experience. And we are pleased to share these with others.\n\n\nNEST (Now and Future)\nVincent Shen (Roche)\nOver the past 5 years, NEST has evolved from a small proof of concept to a well established project containing numerous R packages for streamlining analyses in clinical reporting and beyond. With ever-increasing engagement from internal and external users, NEST is well positioned to further influence and revolutionize how we generate insights for clinical research in the pharmaceutical industry. In this talk, we will share our development roadmap and highlight ideas and plans that we are actively pursuing for various products under the NEST umbrella. We will also share how open-sourcing and collaboration with other companies have benefited us so far in NEST, as well as our mid-to-long term vision of the project.\n\n\nECD liveTFL: Experience and feedback on an application based on the teal framework\nKaiping Yang (Beigene)\nThis paper introduces a web app called ECD liveTFL, which is developed based on the R-based teal framework. The app allows users to select different clinical trial studies and snapshot dates through UI to generate ADaM data for subsequent TFL analysis. The app consists of two parts: data processing and TFL platform. The data processing part is responsible for data preprocessing according to the user’s selection, and the TFL platform part is responsible for reading the processed data to perform interactive TFL analysis. This paper mainly introduces the extensions that the app has compared to the teal framework, as well as the development experience and feedback. Extensions ECD liveTFL app has the following extensions compared to the teal framework:\n\nExtension: The app extends the interactivity of the teal framework data preprocessing by splitting it into two parts, allowing users to generate different ADaM data according to their own choices.\nImprovement: The app enhances the display function of listing and figure by transforming the existing module, and adds the function of selecting the population analysis set of TFL.\nCustomization: The app builds a configuration file database for different studies and combines it with UI, allowing users to dynamically modify the configuration file and feedback to the server side to generate interactive TFL, improving the customization level of TFL.\nQuality: The app ensures the quality of TFL while maintaining its flexibility by using leader programmer to perform unified authority management. Development experience We also gained some experience in the development process, such as:\nBy building a configuration file database for different studies and combining it with UI, we achieved to let users dynamically modify the configuration file and feedback to the server side to generate interactive TFL, further enhancing the interactivity of TFL on more details. By using leader programmer to perform unified authority management, we ensured the quality of TFL while maintaining its flexibility.\nBy transforming the existing module, we enhanced the display function of listing and figure, and added the function of selecting the population analysis set of TFL. Development feedback We also received some feedback in the development process, mainly involving the following aspects:\ntern package: Provide more space for customizing statistical functions and statistical result labels;\nteal package: Add more layout frameworks and drop-down tabs functions;\nteal.reporter package: Enhance PDF and PPT rendering effects and custom style functions, and add a default function to download all TFL content.\n\n\n\nExploring the Advantages of R Admiral Package Over SAS Procedure for Programming ADaM Datasets\nGao Shuang (Beigene)\nR Admiral is an R package designed for programming ADaM datasets and streamlining the data preparation and analysis process. Compared to SAS procedure, R Admiral package has several advantages: • R Admiral is built on a modular approach where an ADaM dataset is constructed through a sequence of derivations. This feature allows for easy adjustments to the code by adding, removing, or modifying derivations. • R Admiral simplifies the data cleaning and tidying process, making data manipulation more flexible and easier to understand. In contrast, SAS uses programs like PROC SQL and PROC Transpose to achieve similar functions. • R Admiral offers more user-defined functions that can meet specific requirements.\nWhile both R Admiral and SAS can generate datasets, their syntax, libraries, and costs may influence the decision on which tool to use for a particular task. This topic compares the differences between the procedures/functions provided by SAS and R Admiral for generating ADaM datasets.\n\n\nTransfer learning of Teal packages\nZhou Kai (AstraZeneca)\nTeal is an open source framework for building interactive clinical reporting Shiny APP. AZ China team decided to adopt it as a supplement tool for TLF generation a year ago. It turned out that this tool can be very useful to generate interactive TLF in a very short time in line with high quality. But meanwhile, we encountered a lot of challenges and problems. We’d like to share with you our experience from AZ programming perspective.\n\n\nRevolutionize Data Exploration with Teal\nChendi Liao (Roche)\n{Teal} is an innovative open-source and scalable R-shiny based framework for interactive data analysis and exploration. It enables data scientists to streamline the creation of web applications, bringing data closer and faster to stakeholders, resulting in quicker insights and better-informed decisions. The framework’s features, such as dynamic data filtering, code reproducibility and report generation, elevate the user experience and promote transparency in the data exploration process. With over 50 analysis templates and the ability to easily integrate customized modules for different analyses or data types, {teal} offers a comprehensive and extendable solution for data exploration. In this talk, we will introduce the {teal} framework, highlight its key features, and share how this has been adopted by hundreds of data scientists inside our organization. For more information about {teal}, please visit https://insightsengineering.github.io/teal/.\n\n\nTable, Listings, and Graphs (TLG) Generation in Using tidytlg\nChinghan Hsiao (Janssen China Research & Development)\nIn recent years, there has been rapid growth in the adoption of open-source technologies. An increasing number of pharmaceutical companies are embracing R as a viable alternative to SAS or as supplementary software for clinical trial reporting. Gaining true proficiency in R, like any programming language, is a process that demands time, effort, and practical experience. Therefore, Janssen R&D has developed the tidytlg package to facilitate the smooth transition of programmers from SAS to R, this package has been released on GitHub.\nThe primary objective of the tidytlg package is to enable the creation of tables, listings, and graphs (TLG) for clinical study reports using the Tidyverse package. This can be achieved through two main methods with this package: 1. Functional method: Building a custom script for each TLG. 2. Metadata method: Building a generic script that utilizes column and table metadata to produce each TLG result. This package provides a framework for creating TLG outputs. The programming workflow includes the following steps: preparing the environment, processing the data, generating the results, and outputting them.\nIn this presentation, topics will cover a general processing flow for generating tables, listings, and graphs, as well as various functions such as defining column variables, generating analysis rows of summary statistics sequentially, and creating outputs (e.g., freq(), univar(), gentlg())."
  },
  {
    "objectID": "highlights.html",
    "href": "highlights.html",
    "title": "Highlights",
    "section": "",
    "text": "The meeting topics covers three main areas:\n\nOpen-source & Collaboration — many open-sourced R packages were shared at the conference, including NEST packages, {tidytlg}, {mmrm}. Participants were very excited about open-sourcing and sharing.\nExperience Embracing R in Pharma — It was great to see use cases of {admiral} and {tidytlg}, and other effort to support daily work with R to replace SAS, including tlg generations and QC.\nPractical Tips in R — It was great to learn how others encounter and overcome similar issues that we had in the past, and how shiny authentication was implemented, similar TLG templates, debugging tip."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "China Pharma R user group meeting 2024",
    "section": "",
    "text": "2nd China Pharmaceutical Industry R User Group Meeting will be held on March 29, 2024, both on-site and online. On-site meeting locations: Shanghai (Novartis campus), Beijing (MSD campus).\n第二届中国医药行业R用户大会将于2024年3月29日召开。线上线下同步进行。线下会议地点：上海（诺华园区），北京（默沙东园区）。\n\n\n\nKey dates\n\n\n\n\n\n13-Oct-2023\nCall for Papers Opens\n\n\n31-Jan-2024\nCall for Papers Closes\n\n\n1-Feb-2024 to  7-Feb-2024\nAcceptance Notices Sent to Authors\n\n\n5-Feb-2024\nConference Registration Opens\n\n\n8-Mar-2024\nConference Registration Closes\n\n\n22-Mar-2024\nFinal Papers/Slides Due\n\n\n29-Mar-2024\nChina Pharma R User Group meeting"
  },
  {
    "objectID": "reg.html",
    "href": "reg.html",
    "title": "Registration now opens",
    "section": "",
    "text": "Please follow the following Link.\n[IMPORTANT] Please scan the QR code for payment, and note that\n\nattending in person 150 RMB (lunch included).\nattending online 80 RMB.\nNote PharmaR + Name (注明PharmaR +名字).\nScreen save the image, and upload via the registration link.\nFill out Fapiao information at the end."
  }
]